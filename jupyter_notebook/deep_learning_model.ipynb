{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import training dataset\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_path = '/data/'\n",
    "filename = 'input_file.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import sampled training dataset\n",
    "df_samp = pd.read_pickle(root_path + data_path + filename)\n",
    "# remove unnecessary columns\n",
    "df_samp.drop(['visitor_id','session_id','visit_len','pageviews','cust_serv_visit','date'], axis=1, inplace=True)\n",
    "df_samp.is_customer.replace(to_replace=-1, value=0, inplace=True)\n",
    "df_samp = df_samp.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 89862 entries, 1256 to 89860\n",
      "Data columns (total 10 columns):\n",
      "checkout_visit       89862 non-null float32\n",
      "source_id            89862 non-null float32\n",
      "device_id            89862 non-null float32\n",
      "country_id           89862 non-null float32\n",
      "city_id              89862 non-null float32\n",
      "nb_past_visits       89862 non-null float32\n",
      "is_customer          89862 non-null float32\n",
      "nb_past_checkouts    89862 non-null float32\n",
      "last_pageviews       89862 non-null float32\n",
      "last_visit_len       89862 non-null float32\n",
      "dtypes: float32(10)\n",
      "memory usage: 4.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_samp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Feed-Forward Neural Net ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code borrowed from :https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/multilayer_perceptron.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 20 # 1st layer number of features\n",
    "n_hidden_2 = 20 # 2nd layer number of features\n",
    "n_input = 9 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 2 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# define data placeholders\n",
    "x = tf.placeholder(\"float\", shape=[None, n_input])\n",
    "y = tf.placeholder(\"float\", shape=[None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 25.485970318\n",
      "Epoch: 0011 cost= 0.695257530\n",
      "Epoch: 0021 cost= 0.695403543\n",
      "Epoch: 0031 cost= 0.695226603\n",
      "Epoch: 0041 cost= 0.695179830\n",
      "Epoch: 0051 cost= 0.694769020\n",
      "Epoch: 0061 cost= 0.695091939\n",
      "Epoch: 0071 cost= 0.695297793\n",
      "Epoch: 0081 cost= 0.695540762\n",
      "Epoch: 0091 cost= 0.694916498\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "# create interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "# initialize variables\n",
    "sess.run(init)\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.        \n",
    "    total_batch = int(len(df_samp)/batch_size)\n",
    "    # log results for tensorboard\n",
    "#     writer = tf.summary.FileWriter(\"./logs/nn_logs\", sess.graph) # for 0.8\n",
    "#     merged = tf.summary.merge_all()\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        df_tmp = df_samp\n",
    "        batch = df_tmp.loc[random.sample(df_tmp.index.values.tolist(), batch_size),:]\n",
    "        target_samp = batch.pop('checkout_visit')\n",
    "        y_tp = target_samp.values.reshape(-1,1)\n",
    "        batch_y = np.concatenate((y_tp, np.abs(y_tp-1)), axis=1)\n",
    "        batch_y.shape\n",
    "        batch_x = batch.values\n",
    "        batch_x.shape\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        summary, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "        # Write summary\n",
    "        writer.add_summary(summary, epoch)\n",
    "        # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "            \"{:.9f}\".format(avg_cost))\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "df_tmp = df_samp\n",
    "target = df_tmp.pop('checkout_visit')\n",
    "y_tp = target.values.reshape(-1,1)\n",
    "y_all = np.concatenate((y_tp, np.abs(y_tp-1)), axis=1)\n",
    "x_all = df_tmp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.01558065414429 %\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "acc = accuracy.eval(feed_dict={x: x_all, y: y_all}) * 100\n",
    "print('Accuracy: {0:2} %'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
